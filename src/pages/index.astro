---
import { Contact } from "@/components/contact";
import { Heading, Paragraph } from "@/components/ui/text";
import MainLayout from "@/layouts/main.astro";

const workexperience = [
  {
    role: "Founding AI Engineer",
    company: "IndraAstra",
    location: "Bengaluru, India",
    date: { start: "May 2025", end: "Present" },
  },
  {
    role: "Graduate Research Assistant",
    company: "Remote Sensing Lab",
    location: "IIT (BHU) Varanasi",
    date: { start: "Jan 2024", end: " May 2025" },
  },
  {
    role: "Generative AI developer Intern",
    company: "KissanAI",
    location: "Remote",
    date: { start: "May 2024", end: " July 2024" },
  },
  {
    role: "Undergraduate Research Assistant",
    company: "Quantum Information Lab",
    location: "IIT (BHU) Varanasi",
    date: { start: "Dec 2022", end: "Dec 2023" },
  },
];
---

<MainLayout>
  <section class="">
    <div>
      <Heading variant="h3">Akash Singh</Heading>
      <Paragraph className="text-muted-foreground leading-none">Applied AI Researcher</Paragraph>
    </div>

    <Paragraph>
      I'm driven by a fundamental question: what does it really mean to be intelligent and how can we built it? This curiosity shapes my research in AI and machine learning, where I focus on building systems that don't just perform well, but understand in meaningful ways. <br /><br />
      My work centers on the belief that current AI systems lack crucial structural constraints that would make their learning more robust and interpretable. I'm particularly interested in disentangled representations — the idea that intelligent systems should learn to separate and organize different factors of variation in data, much like how we naturally distinguish between an object's shape, color, and position.
      I explore how structural regularization can guide neural networks toward more principled solutions, creating models that generalize better and reveal clearer insights about what they've learned. <br /><br />
      Beyond the technical challenges, I'm motivated by the deeper implications: if we can build AI that learns interpretable, compositional representations of the world, we move closer to understanding the computational principles underlying intelligence itself — both artificial and natural.
      If that sounds interesting, <Contact client:load>let's connect!</Contact>
    </Paragraph>
  </section>

  <div></div>

  <section>
    <Heading variant="h4">Experience</Heading>

    <div class="space-y-6">
      {
        workexperience.map((exp) => (
          <div class="flex flex-col justify-between gap-2 sm:flex-row-reverse sm:gap-4">
            <Paragraph className="text-sm sm:text-muted-foreground text-muted-foreground/70">
              {exp.date.start} - {exp.date.end}
            </Paragraph>

            <div>
              <Paragraph>{exp.role}</Paragraph>
              <Paragraph className="text-muted-foreground">
                {exp.company} - {exp.location}
              </Paragraph>
            </div>
          </div>
        ))
      }
    </div>
  </section>
</MainLayout>

<style>
  section {
    display: grid;
    gap: calc(var(--spacing) * 10) /* 2.5rem = 40px */;

    @media (width >= 40rem /* 640px */) {
      gap: calc(var(--spacing) * 4) /* 1rem = 16px */;
      grid-template-columns: 1fr 2fr;
    }
  }
</style>
